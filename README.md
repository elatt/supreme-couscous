# Llama2 - 7B
Import the `src/` folder in this repo as a DataRobot Custom Model and pair it with the `[NVIDIA] Triton Inference Server (vLLM backend) (v6+)` environment.

You will need to enter your HuggingFace API Token as a runtime param before deployment.

Note: `1 x NVIDIA A10 | 24GB VRAM | 8 CPU | 32GB RAM` is the recommened minimum resource allocation for running Llama2 - 7B for inference.
